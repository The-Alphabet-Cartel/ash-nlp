# Phase 6: Future Enhancements

**FILE VERSION**: v5.0.5  
**CREATED**: 2026-01-02  
**UPDATED**: 2026-01-02  
**STATUS**: ‚úÖ PHASE 6 COMPLETE  
**Repository**: https://github.com/the-alphabet-cartel/ash-nlp  
**Community**: The Alphabet Cartel - https://discord.gg/alphabetcartel | https://alphabetcartel.org

---

## Overview

This document tracks future enhancements identified during Phase 5 development. These are non-critical improvements that will enhance system robustness, accuracy, and maintainability.

---

## Enhancement Tickets

### FE-001: User Timezone Support for Late Night Detection

**Priority**: Medium  
**Category**: Context Analysis  
**Status**: ‚úÖ COMPLETED (Sprint 2)

**Description**: Currently, late night detection uses server time (UTC). Users in different timezones may have messages incorrectly flagged or missed.

**Proposed Solution**:
- Accept optional `timezone` parameter in API requests
- Store user timezone preferences
- Convert timestamps to user's local time for late night detection

**Implementation (Sprint 2)**:
- Added `user_timezone` parameter to AnalyzeRequest schema
- Added `_convert_to_local_time()` method to TemporalDetector using ZoneInfo
- Updated `analyze()` to accept `user_timezone` and convert all timestamps to local time
- Late night detection, weekend detection, and hour_of_day now use user's local time
- Added `is_valid_timezone()` helper method
- Added `user_timezone` and `local_hour` fields to TemporalAnalysis and TemporalFactorsResponse
- Version: v5.0-6-2.0-1

**Files Modified**:
- `src/context/temporal_detector.py` ‚Üí v5.0-6-2.0-1
- `src/api/schemas.py` ‚Üí v5.0-6-2.0-1
- `tests/phase6/test_sprint2.py` (new)

---

### FE-002: Discord Message Length Validation

**Priority**: Low  
**Category**: Alerting  
**Status**: ‚úÖ COMPLETED (Sprint 4)

**Description**: Discord has a 2000 character limit for messages. Long explanations or conflict summaries could exceed this limit.

**Proposed Solution**:
- Add truncation logic to Discord alerter
- Split long messages into multiple embeds
- Add character count validation before sending

**Implementation (Sprint 4)**:
- Added `DISCORD_LIMITS` constant dict with all official Discord API limits
- Added `truncate_text()` for simple truncation with suffix
- Added `truncate_at_boundary()` for smart truncation at sentence/word boundaries
- Added `calculate_embed_size()` to count total embed characters
- Added `validate_embed_size()` to check against Discord limits
- Updated `Alert.to_discord_embed()` to truncate all fields before sending
- Aggressive description truncation if total exceeds 6000 chars
- Version: v5.0-6-4.0-2

**Files Modified**:
- `src/utils/alerting.py` ‚Üí v5.0-6-4.0-2
- `src/utils/__init__.py` ‚Üí v5.0-6-4.0-1
- `tests/phase6/test_sprint4.py` (new)

---

### FE-003: Token Truncation for Long Inputs

**Priority**: Medium  
**Category**: Model Processing  
**Status**: ‚úÖ COMPLETED (Sprint 2)

**Description**: Very long messages may exceed model token limits, causing truncation at unpredictable points.

**Proposed Solution**:
- Implement smart truncation that preserves sentence boundaries
- Add configurable max token limits per model
- Log truncation events for monitoring

**Implementation (Sprint 2)**:
- Created `src/utils/text_truncation.py` with `TextTruncator` class
- Supports three strategies: `smart` (preserves sentences), `head`, and `tail`
- Added `max_input_tokens` and `truncation_strategy` to models config
- Updated `BaseModelWrapper` with `_truncate_text()` method
- Smart truncation preserves sentence boundaries and prioritizes recent content
- Token estimation uses 4 chars/token heuristic
- Factory function: `create_text_truncator()`
- Version: v5.0-6-2.0-1

**Files Modified**:
- `src/utils/text_truncation.py` (new) ‚Üí v5.0-6-2.0-1
- `src/utils/__init__.py` ‚Üí v5.0-6-2.0-1
- `src/models/base.py` ‚Üí v5.0-6-2.0-1
- `src/config/default.json` ‚Üí v5.0-6-2.0-1
- `tests/phase6/test_sprint2.py` (new)

---

### FE-004: Model Warm-up on Container Start

**Priority**: Low  
**Category**: Performance  
**Status**: ‚úÖ COMPLETED (Sprint 4)

**Description**: First request after container start has higher latency due to model loading.

**Proposed Solution**:
- Add startup hook to pre-warm models
- Run dummy inference during initialization
- Add health check that waits for warm-up

**Implementation (Sprint 4)**:
- Note: Warmup already existed since Phase 3.7.1, enhanced with detailed tracking
- Added `WarmupResult` dataclass with success, timing, per-model latency, models_warmed
- Updated `warmup()` method to return `WarmupResult` instead of bool
- Added `get_warmup_result()` method to retrieve last warmup result
- Sequential inference used during warmup for accurate per-model timing
- Updated `app.py` startup to use enhanced warmup result
- Version: v5.0-6-4.0-1

**Files Modified**:
- `src/ensemble/decision_engine.py` ‚Üí v5.0-6-4.0-1
- `src/ensemble/__init__.py` ‚Üí v5.0-6-4.0-1
- `src/api/app.py` ‚Üí v5.0-6-4.0-1
- `tests/phase6/test_sprint4.py` (new)

---

### FE-005: Configurable Escalation Thresholds per Severity

**Priority**: Medium  
**Category**: Context Analysis  
**Status**: ‚úÖ COMPLETED (Sprint 3)

**Description**: Different severity levels may need different escalation detection thresholds.

**Proposed Solution**:
- Add per-severity threshold configuration
- Allow stricter thresholds for lower severities
- Provide presets (conservative, balanced, sensitive)

**Implementation (Sprint 3)**:
- Added `SeverityThreshold` dataclass with `score_increase_threshold`, `minimum_messages`, `rapid_threshold_hours`
- Added `ThresholdPreset` dataclass for preset configurations
- Updated `EscalationDetectionConfig` with `per_severity_thresholds` and `threshold_presets` dictionaries
- Added `get_threshold_for_severity()` and `get_preset()` methods to config
- Updated `context_config.json` with per-severity thresholds for critical/high/medium/low/safe
- Added three threshold presets: conservative, balanced, sensitive
- New `analyze_with_severity()` method in `EscalationDetector`
- Uses severity-specific thresholds for more sensitive detection at higher severity levels
- Version: v5.0-6-3.0-1

**Files Modified**:
- `src/config/context_config.json` ‚Üí v5.0-6-3.0-1
- `src/managers/context_config_manager.py` ‚Üí v5.0-6-3.0-1
- `src/managers/__init__.py` ‚Üí v5.0-6-3.0-1
- `src/context/escalation_detector.py` ‚Üí v5.0-6-3.0-1
- `tests/phase6/test_sprint3.py` (new)

---

### FE-006: Historical Pattern Learning

**Priority**: High  
**Category**: Machine Learning  
**Status**: üîÆ DEFERRED TO v5.1

**Description**: System could learn from past escalation patterns to improve prediction accuracy.

**Proposed Solution**:
- Store anonymized escalation sequences
- Train lightweight pattern recognition model
- Use historical data to improve confidence scores

**Deferral Reason (2026-01-02)**:
Deferred to v5.1 to allow stabilization of the current v5.0 system across the Ash ecosystem before adding complex ML learning features. This ensures the foundation is solid before expanding functionality.

**Files Affected**:
- New module: `src/learning/`
- Database integration required

---

### FE-007: Message History Passthrough Investigation

**Priority**: Medium  
**Category**: Bug Investigation  
**Status**: ‚úÖ COMPLETED (Sprint 3)

**Description**: During integration testing, some edge cases showed unexpected behavior with message history passthrough.

**Proposed Solution**:
- Add detailed logging for history processing
- Create comprehensive edge case test suite
- Investigate potential race conditions in async processing

**Implementation (Sprint 3)**:
- Created `src/utils/history_debug.py` with comprehensive validation utilities
- New `HistoryValidator` class with validation for:
  - Required fields (message, timestamp)
  - Valid data types and ranges
  - Chronological ordering
  - Score validity (0.0-1.0 range)
  - Edge cases (future timestamps, large gaps, duplicates)
- `HistoryIssue` enum for categorized validation issues
- `HistoryValidationResult` dataclass with detailed statistics
- `HistoryDebugLogger` class for structured FE-007 logging throughout processing pipeline
- Factory functions: `create_history_validator()`, `create_history_debug_logger()`, `validate_history()`
- Version: v5.0-6-3.0-1

**Files Modified**:
- `src/utils/history_debug.py` (new) ‚Üí v5.0-6-3.0-1
- `src/utils/__init__.py` ‚Üí v5.0-6-3.0-1
- `tests/phase6/test_sprint3.py` (new)

---

### FE-008: Enhanced Ensemble Conflict Webhook Alerts

**Priority**: Low  
**Category**: Alerting  
**Status**: ‚úÖ COMPLETED (Sprint 4)

**Description**: Conflict detection could trigger specialized Discord alerts with detailed model disagreement information.

**Proposed Solution**:
- Add conflict-specific alert template
- Include visual disagreement chart (ASCII or image)
- Add configurable conflict alert threshold

**Implementation (Sprint 4)**:
- Added `DEFAULT_CONFLICT_ALERT_THRESHOLD` constant (0.15)
- Added `generate_disagreement_chart()` for ASCII bar chart visualization of model scores
- Added `format_conflict_summary()` for formatted conflict reports with ASCII chart
- Added `conflict_alert_threshold` parameter to `DiscordAlerter.__init__()`
- ASCII chart shows model names, filled/empty bars, scores, range, and variance
- Version: v5.0-6-4.0-2

**Files Modified**:
- `src/utils/alerting.py` ‚Üí v5.0-6-4.0-2
- `src/utils/__init__.py` ‚Üí v5.0-6-4.0-1
- `tests/phase6/test_sprint4.py` (new)

---

### FE-009: Suppress Webhooks During Test Execution

**Priority**: High  
**Category**: Testing  
**Status**: ‚úÖ COMPLETED (Sprint 1)

**Description**: Test runs may trigger real Discord webhooks, causing noise in production channels.

**Proposed Solution**:
- Add `TESTING_MODE` environment variable check
- Mock webhook calls during pytest execution
- Add dry-run mode for alerting system

**Implementation (Sprint 1)**:
- Added `testing_mode` parameter to DiscordAlerter that auto-detects from `NLP_ENVIRONMENT=testing`
- Webhooks are suppressed but tracked in `_suppressed_alerts` list
- Added helper methods: `is_testing_mode()`, `get_suppressed_alerts()`, `set_alert_callback()`
- Added `mock_alerter` and `alert_callback_tracker` fixtures to conftest.py
- Version: v5.0-6-1.0-1

**Files Modified**:
- `src/utils/alerting.py` ‚Üí v5.0-6-1.0-1
- `tests/conftest.py` ‚Üí v5.0-6-1.0-1

---

### FE-010: Config File Docker Volume Mapping

**Priority**: Low  
**Category**: Testing / DevOps  
**Status**: ‚úÖ COMPLETED (Sprint 1)

**Description**: Tests expect config files at `/app/config/` but actual configs are in `src/config/`. Docker volume mapping differs from test expectations.

**Current Workaround**: 3 tests skipped in `tests/phase3/test_config.py`

**Proposed Solution**:
- Align test paths with actual Docker volume mapping
- Or update Dockerfile to copy configs to expected location
- Or make tests dynamically detect config location

**Implementation (Sprint 1)**:
- Added `_get_config_paths()` helper that dynamically detects config directories
- Tests now check multiple possible locations: `/app/config`, `/app/src/config`, `src/config`, etc.
- Tests pass if config files found in ANY valid location
- Version: v5.0-6-1.0-1

**Files Modified**:
- `tests/phase3/test_config.py` ‚Üí v5.0-6-1.0-1

**Previously Skipped Tests (Now Active)**:
- `test_default_config_exists` ‚úÖ
- `test_production_config_exists` ‚úÖ
- `test_testing_config_exists` ‚úÖ

---

### FE-011: Consensus Threshold Edge Cases

**Priority**: Low  
**Category**: Testing  
**Status**: ‚úÖ COMPLETED (Sprint 1)

**Description**: Some consensus algorithm tests fail due to edge cases:
1. Majority threshold uses `>` not `>=` comparison (0.25 == 0.25 returns False)
2. Test fixture variance (0.099) is below disagreement threshold (0.15)

**Current Workaround**: 3 tests skipped in `tests/phase4/test_consensus.py`

**Proposed Solution**:
- Option A: Update implementation to use `>=` for inclusive thresholds
- Option B: Update test fixtures to have higher variance data
- Option C: Adjust test expectations to match actual behavior

**Implementation (Sprint 1)**:
- Used Option B: Updated test fixtures with more extreme data
- `test_majority_threshold_configurable`: Changed to 0.4/0.6 thresholds with 50% vote ratio (clearly crosses boundaries)
- `test_disagreement_flags_conflict`: Added extreme scores (0.95 vs 0.05) with variance ~0.203 > 0.15 threshold
- `test_significant_disagreement_high_variance`: Same extreme data approach
- Version: v5.0-6-1.0-1

**Files Modified**:
- `tests/phase4/test_consensus.py` ‚Üí v5.0-6-1.0-1

**Previously Skipped Tests (Now Active)**:
- `test_majority_threshold_configurable` ‚úÖ
- `test_disagreement_flags_conflict` ‚úÖ
- `test_significant_disagreement_high_variance` ‚úÖ

---

### FE-012: Time-Sensitive Tests and Smoothing Algorithm

**Priority**: Low  
**Category**: Testing  
**Status**: ‚úÖ COMPLETED (Sprint 1)

**Description**: Several context analyzer tests fail due to:
1. Tests run at 3am UTC which triggers late night detection
2. Smoothing algorithm reduces peak scores (0.8‚Üí0.633, 1.0‚Üí0.75)

**Current Workaround**: 3 tests skipped in `tests/phase5/test_context_analyzer.py`

**Proposed Solution**:
- Mock `datetime.now()` in temporal tests
- Use explicit timestamps that are timezone-aware
- Adjust test expectations to account for smoothing effects
- Or test raw scores before smoothing is applied

**Implementation (Sprint 1)**:
- `test_normal_hours`: Mocked datetime and passed explicit `current_timestamp=afternoon`
- `test_trajectory_peak_score`: Increased peak score (0.95) and lowered threshold (>= 0.6)
- `test_very_high_current_score`: Changed expectation from exact 1.0 to >= 0.7
- Version: v5.0-6-1.0-1

**Files Modified**:
- `tests/phase5/test_context_analyzer.py` ‚Üí v5.0-6-1.0-1

**Previously Skipped Tests (Now Active)**:
- `test_normal_hours` ‚úÖ
- `test_trajectory_peak_score` ‚úÖ
- `test_very_high_current_score` ‚úÖ

---

## Priority Matrix

| Priority | Tickets | Focus Area | Status |
|----------|---------|------------|--------|
| **High** | ~~FE-006~~, ~~FE-009~~ | ~~ML Learning~~, ~~Test Isolation~~ | FE-006 ‚Üí v5.1, FE-009 ‚úÖ |
| **Medium** | ~~FE-001~~, ~~FE-003~~, ~~FE-005~~, ~~FE-007~~ | ~~Accuracy~~, ~~Robustness~~ | All ‚úÖ |
| **Low** | ~~FE-002~~, ~~FE-004~~, ~~FE-008~~, ~~FE-010~~, ~~FE-011~~, ~~FE-012~~ | ~~Polish~~, ~~Test Fixes~~ | All ‚úÖ |

---

## Skipped Tests Summary

| Ticket | Phase | Count | Status |
|--------|-------|-------|--------|
| FE-010 | 3 | 3 | ‚úÖ Fixed (Sprint 1) |
| FE-011 | 4 | 3 | ‚úÖ Fixed (Sprint 1) |
| FE-012 | 5 | 3 | ‚úÖ Fixed (Sprint 1) |
| **Total** | | **0** | **All Fixed!** |

üéâ All previously skipped tests have been fixed and are now active.

---

## Implementation Notes

### Before Starting Phase 6

1. ~~Ensure all Phase 5 tests pass (426/435, 9 skipped)~~ ‚úÖ Sprint 1 fixed all skipped tests!
2. Review production logs for any recurring issues
3. Gather community feedback on current detection accuracy
4. Prioritize based on real-world usage patterns

### Sprint 1 Completed (2026-01-02)

‚úÖ **FE-009**: Test webhook suppression - auto-detects `NLP_ENVIRONMENT=testing`  
‚úÖ **FE-010**: Config path tests - dynamic path detection  
‚úÖ **FE-011**: Consensus threshold tests - extreme variance test data  
‚úÖ **FE-012**: Time/smoothing tests - datetime mocking + adjusted expectations  

**Test Count**: 435/435 passing (0 skipped) üéâ

### Suggested Sprint Order

1. ~~**Sprint 1**: FE-009 (test isolation) + FE-010/011/012 (fix skipped tests)~~ ‚úÖ COMPLETED
2. ~~**Sprint 2**: FE-001 (timezone) + FE-003 (token truncation)~~ ‚úÖ COMPLETED
3. ~~**Sprint 3**: FE-005 (per-severity thresholds) + FE-007 (investigation)~~ ‚úÖ COMPLETED
4. ~~**Sprint 4**: FE-002, FE-004, FE-008 (polish items)~~ ‚úÖ COMPLETED
5. ~~**Sprint 5**: FE-006 (historical learning)~~ üîÆ DEFERRED TO v5.1

### Sprint 2 Completed (2026-01-02)

‚úÖ **FE-001**: User Timezone Support
- Added `user_timezone` parameter to API requests
- Temporal detection uses user's local time for late night and weekend detection
- ZoneInfo-based timezone conversion with fallback handling
- New fields: `user_timezone`, `local_hour` in responses

‚úÖ **FE-003**: Token Truncation
- New `TextTruncator` class with smart, head, and tail strategies
- Smart truncation preserves sentence boundaries
- Configurable via `max_input_tokens` and `truncation_strategy` in config
- Integrated into `BaseModelWrapper.analyze()` method

**New Test File**: `tests/phase6/test_sprint2.py`
- 14 new tests for timezone and truncation features
- Integration tests for schema and config validation

### Sprint 3 Completed (2026-01-02)

‚úÖ **FE-005**: Per-Severity Escalation Thresholds
- New `SeverityThreshold` and `ThresholdPreset` dataclasses
- Per-severity thresholds: critical (0.15), high (0.20), medium (0.30), low (0.40), safe (0.50)
- Three threshold presets: conservative, balanced, sensitive
- New `analyze_with_severity()` method uses severity-specific detection thresholds
- Higher severity levels trigger on smaller score increases

‚úÖ **FE-007**: History Validation and Debug Utilities
- New `HistoryValidator` class with comprehensive validation
- Detects: missing fields, invalid timestamps, out-of-order data, large gaps, score range issues
- `HistoryDebugLogger` for structured debugging throughout history pipeline
- `HistoryIssue` enum categorizes 12+ types of validation issues
- Factory functions for easy instantiation

**New Test File**: `tests/phase6/test_sprint3.py`
- Tests for per-severity thresholds
- Tests for history validation edge cases
- Integration tests for Sprint 3 features

### Sprint 4 Completed (2026-01-02)

‚úÖ **FE-002**: Discord Message Length Validation
- Added `DISCORD_LIMITS` constant dict with all official Discord API limits
- `truncate_text()` for simple truncation with suffix
- `truncate_at_boundary()` for smart truncation at sentence/word boundaries
- `calculate_embed_size()` and `validate_embed_size()` for embed validation
- `Alert.to_discord_embed()` now truncates all fields before sending

‚úÖ **FE-004**: Model Warm-up Enhancement
- Note: Warmup already existed since Phase 3.7.1, enhanced with detailed tracking
- Added `WarmupResult` dataclass with success, timing, per-model latency
- Updated `warmup()` to return `WarmupResult` instead of bool
- Added `get_warmup_result()` method to retrieve last warmup result
- Sequential inference during warmup for accurate per-model timing

‚úÖ **FE-008**: Enhanced Conflict Alerts
- Added `DEFAULT_CONFLICT_ALERT_THRESHOLD` constant (0.15)
- `generate_disagreement_chart()` for ASCII bar chart visualization
- `format_conflict_summary()` for formatted conflict reports with ASCII chart
- Added `conflict_alert_threshold` parameter to `DiscordAlerter`

**New Test File**: `tests/phase6/test_sprint4.py`
- Tests for Discord limits and truncation (FE-002)
- Tests for WarmupResult dataclass (FE-004)
- Tests for ASCII chart and conflict threshold (FE-008)

---

## üéâ Phase 6 Complete!

**Completion Date**: 2026-01-02

### Summary

Phase 6 successfully delivered 11 enhancement tickets across 4 sprints:

| Sprint | Tickets | Focus |
|--------|---------|-------|
| Sprint 1 | FE-009, FE-010, FE-011, FE-012 | Test isolation & fixes |
| Sprint 2 | FE-001, FE-003 | Timezone support & token truncation |
| Sprint 3 | FE-005, FE-007 | Per-severity thresholds & history validation |
| Sprint 4 | FE-002, FE-004, FE-008 | Discord limits, warmup tracking, conflict alerts |

### Deferred to v5.1

- **FE-006**: Historical Pattern Learning - deferred to allow ecosystem stabilization

### Key Achievements

- ‚úÖ **435/435 tests passing** (0 skipped)
- ‚úÖ User timezone support for accurate late-night detection
- ‚úÖ Smart text truncation preserving sentence boundaries
- ‚úÖ Per-severity escalation thresholds with presets
- ‚úÖ Comprehensive history validation utilities
- ‚úÖ Discord message length validation and truncation
- ‚úÖ Enhanced model warm-up with detailed timing
- ‚úÖ ASCII disagreement charts for conflict alerts
- ‚úÖ Test webhook suppression in testing mode

### Next Steps

1. Deploy v5.0 to production
2. Monitor system stability across Ash ecosystem
3. Gather community feedback
4. Plan v5.1 with FE-006 (Historical Pattern Learning)

---

**Built with care for chosen family** üè≥Ô∏è‚Äçüåà
