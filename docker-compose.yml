# Ash-NLP Docker Compose for Ash Ecosystem
# Repository: https://github.com/the-alphabet-cartel/ash-nlp
# Discord: https://discord.gg/alphabetcartel
# Website: http://alphabetcartel.org
services:
  # ========================================================================
  # NLP Server (ash-nlp)
  # ========================================================================
  ash-nlp:
#    build:
#      context: .
    image: ghcr.io/the-alphabet-cartel/ash-nlp:latest
    container_name: ash-nlp
    restart: unless-stopped
    networks:
      ash-network:
        ipv4_address: 172.20.0.11
    ports:
      - 8881:8881
    environment:
      # Local Timezone
      - TZ=America/Los_Angeles
      
      # Secrets
      - GLOBAL_HUGGINGFACE_TOKEN=${GLOBAL_HUGGINGFACE_TOKEN}
      - GLOBAL_CLAUDE_API_KEY=${GLOBAL_CLAUDE_API_KEY}

      # Hugging Face Configuration
      - NLP_HUGGINGFACE_CACHE_DIR=${NLP_HUGGINGFACE_CACHE_DIR}
      
      # Mode
      - NLP_ENSEMBLE_MODE=${NLP_ENSEMBLE_MODE:-consensus}

      # Learning System Configuration
      - GLOBAL_ENABLE_LEARNING_SYSTEM=${GLOBAL_ENABLE_LEARNING_SYSTEM:-true}
      - NLP_LEARNING_RATE=${NLP_LEARNING_RATE:-0.1}
      - NLP_MAX_LEARNING_ADJUSTMENTS_PER_DAY=${NLP_MAX_LEARNING_ADJUSTMENTS_PER_DAY:-50}
      - NLP_LEARNING_PERSISTENCE_FILE=${NLP_LEARNING_PERSISTENCE_FILE}
      - NLP_MIN_CONFIDENCE_ADJUSTMENT=${NLP_MIN_CONFIDENCE_ADJUSTMENT:-0.05}
      - NLP_MAX_CONFIDENCE_ADJUSTMENT=${NLP_MAX_CONFIDENCE_ADJUSTMENT:-0.30}
      
      # Additional Model Manager Settings
      - NLP_USE_FAST_TOKENIZER=${NLP_USE_FAST_TOKENIZER:-true}
      - NLP_TRUST_REMOTE_CODE=${NLP_TRUST_REMOTE_CODE:-false}
      - NLP_MODEL_REVISION=${NLP_MODEL_REVISION:-main}

      # Model Configuration
      - NLP_DEPRESSION_MODEL=${NLP_DEPRESSION_MODEL:-MoritzLaurer/deberta-v3-base-zeroshot-v2.0}
      - NLP_SENTIMENT_MODEL=${NLP_SENTIMENT_MODEL:-MoritzLaurer/mDeBERTa-v3-base-mnli-xnli}
      - NLP_EMOTIONAL_DISTRESS_MODEL=${NLP_EMOTIONAL_DISTRESS_MODEL:-Lowerated/lm6-deberta-v3-topic-sentiment}
      - NLP_MODEL_CACHE_DIR=${NLP_MODEL_CACHE_DIR}
      
      # Hardware Configuration
      - NLP_DEVICE=${NLP_DEVICE:-auto}
      - NLP_MODEL_PRECISION=${NLP_MODEL_PRECISION:-float16}
      
      # Performance Tuning
      - NLP_MAX_BATCH_SIZE=${NLP_MAX_BATCH_SIZE:-32}
      - NLP_INFERENCE_THREADS=${NLP_INFERENCE_THREADS:-4}
      - NLP_MAX_CONCURRENT_REQUESTS=${NLP_MAX_CONCURRENT_REQUESTS:-10}
      - NLP_REQUEST_TIMEOUT=${NLP_REQUEST_TIMEOUT:-30}
      
      # Server Configuration
      - GLOBAL_NLP_API_PORT=${GLOBAL_NLP_API_PORT:-8881}
      - NLP_UVICORN_WORKERS=${NLP_UVICORN_WORKERS:-1}
      - NLP_RELOAD_ON_CHANGES=${NLP_RELOAD_ON_CHANGES:-false}
      
      # Logging Configuration
      - GLOBAL_LOG_LEVEL=${GLOBAL_LOG_LEVEL:-INFO}
      - NLP_LOG_FILE=${NLP_LOG_FILE:-nlp_service.log}
      - NLP_FLIP_SENTIMENT_LOGIC=${NLP_FLIP_SENTIMENT_LOGIC:-false}
      
      # Storage Paths
      - NLP_DATA_DIR=${NLP_DATA_DIR}
      - NLP_MODELS_DIR=${NLP_MODELS_DIR}
      - NLP_LOGS_DIR=${NLP_LOGS_DIR}
      - NLP_LEARNING_DATA_DIR=${NLP_LEARNING_DATA_DIR}
      
      # Zero-Shot Labels
      ## Options: current, enhanced_crisis, clinical_focused, conversational, safety_first
      - NLP_ZERO_SHOT_LABEL_SET=${NLP_ZERO_SHOT_LABEL_SET:-enhanced_crisis}
      - NLP_ENABLE_LABEL_SET_SWITCHING=${NLP_ENABLE_LABEL_SET_SWITCHING:-true}
      ## Zero-Shot Label Testing
      - NLP_INCLUDE_RAW_LABELS=${NLP_INCLUDE_RAW_LABELS:-true}
      ## Log label mapping decisions for analysis
      - NLP_LOG_LABEL_MAPPINGS=${NLP_LOG_LABEL_MAPPINGS:-true}
      ## Enable label performance tracking
      - NLP_TRACK_LABEL_PERFORMANCE=${NLP_TRACK_LABEL_PERFORMANCE:-true}

      # UPDATED: Individual model thresholds (if you use them)
      - NLP_HIGH_CRISIS_THRESHOLD=${NLP_HIGH_CRISIS_THRESHOLD:-0.45}
      - NLP_MEDIUM_CRISIS_THRESHOLD=${NLP_MEDIUM_CRISIS_THRESHOLD:-0.25}
      - NLP_LOW_CRISIS_THRESHOLD=${NLP_LOW_CRISIS_THRESHOLD:-0.15}

      # UPDATED: Legacy ensemble thresholds (if you use them)
      - NLP_ENSEMBLE_HIGH_CRISIS_THRESHOLD=${NLP_ENSEMBLE_HIGH_CRISIS_THRESHOLD:-0.45}
      - NLP_ENSEMBLE_MEDIUM_CRISIS_THRESHOLD=${NLP_ENSEMBLE_MEDIUM_CRISIS_THRESHOLD:-0.25}
      - NLP_ENSEMBLE_LOW_CRISIS_THRESHOLD=${NLP_ENSEMBLE_LOW_CRISIS_THRESHOLD:-0.12}
      
      # Additional threshold controls (new)
      - NLP_MILD_CRISIS_THRESHOLD=${NLP_MILD_CRISIS_THRESHOLD:-0.25}
      - NLP_NEGATIVE_RESPONSE_THRESHOLD=${NLP_NEGATIVE_RESPONSE_THRESHOLD:-0.65}
      - NLP_UNKNOWN_RESPONSE_THRESHOLD=${NLP_UNKNOWN_RESPONSE_THRESHOLD:-0.45}
      
      # Safety controls (new)
      - NLP_CONSENSUS_SAFETY_BIAS=${NLP_CONSENSUS_SAFETY_BIAS:-0.05}
      - NLP_ENABLE_SAFETY_OVERRIDE=${NLP_ENABLE_SAFETY_OVERRIDE:-true}
      
      # UPDATED: Model weights
      - NLP_DEPRESSION_MODEL_WEIGHT=${NLP_DEPRESSION_MODEL_WEIGHT:-0.6}
      - NLP_SENTIMENT_MODEL_WEIGHT=${NLP_SENTIMENT_MODEL_WEIGHT:-0.15}
      - NLP_EMOTIONAL_DISTRESS_MODEL_WEIGHT=${NLP_EMOTIONAL_DISTRESS_MODEL_WEIGHT:-0.25}
      
      # UPDATED: Gap detection thresholds
      - NLP_GAP_DETECTION_THRESHOLD=${NLP_GAP_DETECTION_THRESHOLD:-0.25}
      - NLP_DISAGREEMENT_THRESHOLD=${NLP_DISAGREEMENT_THRESHOLD:-0.35}
      - NLP_AUTO_FLAG_DISAGREEMENTS=${NLP_AUTO_FLAG_DISAGREEMENTS:-true}
      
      # NEW: Primary consensus mapping thresholds
      - NLP_CONSENSUS_CRISIS_TO_HIGH_THRESHOLD=${NLP_CONSENSUS_CRISIS_TO_HIGH_THRESHOLD:-0.50}
      - NLP_CONSENSUS_CRISIS_TO_MEDIUM_THRESHOLD=${NLP_CONSENSUS_CRISIS_TO_MEDIUM_THRESHOLD:-0.30}
      - NLP_CONSENSUS_MILD_CRISIS_TO_LOW_THRESHOLD=${NLP_CONSENSUS_MILD_CRISIS_TO_LOW_THRESHOLD:-0.40}
      - NLP_CONSENSUS_NEGATIVE_TO_LOW_THRESHOLD=${NLP_CONSENSUS_NEGATIVE_TO_LOW_THRESHOLD:-0.70}
      - NLP_CONSENSUS_UNKNOWN_TO_LOW_THRESHOLD=${NLP_CONSENSUS_UNKNOWN_TO_LOW_THRESHOLD:-0.50}
      
      # NEW: Staff review thresholds
      - NLP_STAFF_REVIEW_HIGH_ALWAYS=${NLP_STAFF_REVIEW_HIGH_ALWAYS:-true}
      - NLP_STAFF_REVIEW_MEDIUM_CONFIDENCE_THRESHOLD=${NLP_STAFF_REVIEW_MEDIUM_CONFIDENCE_THRESHOLD:-0.45}
      - NLP_STAFF_REVIEW_LOW_CONFIDENCE_THRESHOLD=${NLP_STAFF_REVIEW_LOW_CONFIDENCE_THRESHOLD:-0.75}
      - NLP_STAFF_REVIEW_ON_MODEL_DISAGREEMENT=${NLP_STAFF_REVIEW_ON_MODEL_DISAGREEMENT:-true}
      
      # NEW: Safety controls
      - NLP_CONSENSUS_SAFETY_BIAS=${NLP_CONSENSUS_SAFETY_BIAS:-0.03}
      - NLP_ENABLE_SAFETY_OVERRIDE=${NLP_ENABLE_SAFETY_OVERRIDE:-true}

      # Rate Limiting
      - NLP_MAX_REQUESTS_PER_MINUTE=${NLP_MAX_REQUESTS_PER_MINUTE:-60}
      - NLP_MAX_REQUESTS_PER_HOUR=${NLP_MAX_REQUESTS_PER_HOUR:-1000}
      
      # Security
      - GLOBAL_ALLOWED_IPS=${GLOBAL_ALLOWED_IPS}
      - GLOBAL_ENABLE_CORS=${GLOBAL_ENABLE_CORS}

      # Experimental Features
      - NLP_ENABLE_ENSEMBLE_ANALYSIS=${NLP_ENABLE_ENSEMBLE_ANALYSIS:-true}
      - NLP_ENABLE_GAP_DETECTION=${NLP_ENABLE_GAP_DETECTION:-true}
      - NLP_ENABLE_CONFIDENCE_SPREADING=${NLP_ENABLE_CONFIDENCE_SPREADING:-true}
      - NLP_LOG_MODEL_DISAGREEMENTS=${NLP_LOG_MODEL_DISAGREEMENTS:-true}
      
      # Phase 3a - Crisis Pattern Configuration
      - NLP_CONFIG_ENABLE_CRISIS_PATTERNS=${NLP_CONFIG_ENABLE_CRISIS_PATTERNS:-true}
      - NLP_CONFIG_ENABLE_LGBTQIA_PATTERNS=${NLP_CONFIG_ENABLE_LGBTQIA_PATTERNS:-true}
      - NLP_CONFIG_ENABLE_POSITIVE_CONTEXTS=${NLP_CONFIG_ENABLE_POSITIVE_CONTEXTS:-true}
      - NLP_CONFIG_CRISIS_CONTEXT_BOOST_MULTIPLIER=${NLP_CONFIG_CRISIS_CONTEXT_BOOST_MULTIPLIER:-1.0}
      - NLP_CONFIG_LGBTQIA_WEIGHT_MULTIPLIER=${NLP_CONFIG_LGBTQIA_WEIGHT_MULTIPLIER:-1.0}
      - NLP_CONFIG_BURDEN_WEIGHT_MULTIPLIER=${NLP_CONFIG_BURDEN_WEIGHT_MULTIPLIER:-1.2}
      - NLP_CONFIG_ENHANCED_CRISIS_WEIGHT=${NLP_CONFIG_ENHANCED_CRISIS_WEIGHT:-1.2}

      # Phase 3b - Analysis Parameters Configuration
      # ============== CRISIS THRESHOLDS ==========================================
      # Core crisis level mapping thresholds for analysis algorithms
      - NLP_ANALYSIS_CRISIS_THRESHOLD_HIGH=${NLP_ANALYSIS_CRISIS_THRESHOLD_HIGH:-0.55}    # Reduced from 0.50 - matches systematic approach
      - NLP_ANALYSIS_CRISIS_THRESHOLD_MEDIUM=${NLP_ANALYSIS_CRISIS_THRESHOLD_MEDIUM:-0.28}  # Reduced from 0.22 - more selective for medium alerts
      - NLP_ANALYSIS_CRISIS_THRESHOLD_LOW=${NLP_ANALYSIS_CRISIS_THRESHOLD_LOW:-0.16}     # Reduced from 0.12 - avoids very mild expressions
      
      # ============== PHRASE EXTRACTION PARAMETERS ===============================
      # Parameters for crisis phrase extraction from messages
      - NLP_ANALYSIS_MIN_PHRASE_LENGTH=${NLP_ANALYSIS_MIN_PHRASE_LENGTH:-2}           # Minimum length for extracted phrases
      - NLP_ANALYSIS_MAX_PHRASE_LENGTH=${NLP_ANALYSIS_MAX_PHRASE_LENGTH:-6}           # Maximum length for extracted phrases
      - NLP_ANALYSIS_PHRASE_CRISIS_FOCUS=${NLP_ANALYSIS_PHRASE_CRISIS_FOCUS:-true}      # Focus on crisis-related phrases
      - NLP_ANALYSIS_PHRASE_COMMUNITY_SPECIFIC=${NLP_ANALYSIS_PHRASE_COMMUNITY_SPECIFIC:-true} # Use community-specific patterns
      - NLP_ANALYSIS_PHRASE_MIN_CONFIDENCE=${NLP_ANALYSIS_PHRASE_MIN_CONFIDENCE:-0.3}     # Minimum confidence for phrase extraction
      - NLP_ANALYSIS_PHRASE_MAX_RESULTS=${NLP_ANALYSIS_PHRASE_MAX_RESULTS:-20}         # Maximum number of phrases to return
      
      # ============== PATTERN LEARNING PARAMETERS ================================
      # Parameters for learning distinctive crisis patterns from community messages
      - NLP_ANALYSIS_PATTERN_MIN_CRISIS_MESSAGES=${NLP_ANALYSIS_PATTERN_MIN_CRISIS_MESSAGES:-10}      # Minimum crisis messages for pattern learning
      - NLP_ANALYSIS_PATTERN_MAX_PHRASES_TO_ANALYZE=${NLP_ANALYSIS_PATTERN_MAX_PHRASES_TO_ANALYZE:-200}  # Maximum phrases to analyze
      - NLP_ANALYSIS_PATTERN_MIN_DISTINCTIVENESS_RATIO=${NLP_ANALYSIS_PATTERN_MIN_DISTINCTIVENESS_RATIO:-2.0} # Minimum distinctiveness ratio
      - NLP_ANALYSIS_PATTERN_MIN_FREQUENCY=${NLP_ANALYSIS_PATTERN_MIN_FREQUENCY:-3}             # Minimum frequency for pattern detection
      - NLP_ANALYSIS_PATTERN_HIGH_CONFIDENCE=${NLP_ANALYSIS_PATTERN_HIGH_CONFIDENCE:-0.7}         # High confidence threshold for patterns
      - NLP_ANALYSIS_PATTERN_MEDIUM_CONFIDENCE=${NLP_ANALYSIS_PATTERN_MEDIUM_CONFIDENCE:-0.4}       # Medium confidence threshold for patterns
      - NLP_ANALYSIS_PATTERN_LOW_CONFIDENCE=${NLP_ANALYSIS_PATTERN_LOW_CONFIDENCE:-0.1}          # Low confidence threshold for patterns
      
      # ============== SEMANTIC ANALYSIS PARAMETERS ===============================
      # Parameters for semantic analysis and context understanding
      - NLP_ANALYSIS_SEMANTIC_CONTEXT_WINDOW=${NLP_ANALYSIS_SEMANTIC_CONTEXT_WINDOW:-3}           # Words around community terms
      - NLP_ANALYSIS_SEMANTIC_HIGH_RELEVANCE_BOOST=${NLP_ANALYSIS_SEMANTIC_HIGH_RELEVANCE_BOOST:-0.1}   # Boost for high relevance context
      - NLP_ANALYSIS_SEMANTIC_MEDIUM_RELEVANCE_BOOST=${NLP_ANALYSIS_SEMANTIC_MEDIUM_RELEVANCE_BOOST:-0.05} # Boost for medium relevance context
      - NLP_ANALYSIS_SEMANTIC_FAMILY_REJECTION_BOOST=${NLP_ANALYSIS_SEMANTIC_FAMILY_REJECTION_BOOST:-0.15} # Boost for family rejection indicators
      - NLP_ANALYSIS_SEMANTIC_DISCRIMINATION_FEAR_BOOST=${NLP_ANALYSIS_SEMANTIC_DISCRIMINATION_FEAR_BOOST:-0.15} # Boost for discrimination fear
      - NLP_ANALYSIS_SEMANTIC_SUPPORT_SEEKING_BOOST=${NLP_ANALYSIS_SEMANTIC_SUPPORT_SEEKING_BOOST:--0.05}    # Reduces crisis level (positive context)
      
      # ============== ADVANCED ANALYSIS PARAMETERS ===============================
      # Advanced analysis parameters for fine-tuning algorithm behavior
      - NLP_ANALYSIS_PATTERN_CONFIDENCE_BOOST=${NLP_ANALYSIS_PATTERN_CONFIDENCE_BOOST:-0.05}       # Additional confidence boost from patterns
      - NLP_ANALYSIS_MODEL_CONFIDENCE_BOOST=${NLP_ANALYSIS_MODEL_CONFIDENCE_BOOST:-0.0}          # Additional confidence boost from models
      - NLP_ANALYSIS_CONTEXT_SIGNAL_WEIGHT=${NLP_ANALYSIS_CONTEXT_SIGNAL_WEIGHT:-1.0}           # Weight for context signals
      - NLP_ANALYSIS_TEMPORAL_URGENCY_MULTIPLIER=${NLP_ANALYSIS_TEMPORAL_URGENCY_MULTIPLIER:-1.2}     # Multiplier for temporal urgency
      - NLP_ANALYSIS_COMMUNITY_AWARENESS_BOOST=${NLP_ANALYSIS_COMMUNITY_AWARENESS_BOOST:-0.1}       # Boost for community-aware analysis
      
      # ============== INTEGRATION SETTINGS =======================================
      # Settings for integrating analysis components
      - NLP_ANALYSIS_ENABLE_PATTERN_ANALYSIS=${NLP_ANALYSIS_ENABLE_PATTERN_ANALYSIS:-true}        # Enable pattern-based analysis
      - NLP_ANALYSIS_ENABLE_SEMANTIC_ANALYSIS=${NLP_ANALYSIS_ENABLE_SEMANTIC_ANALYSIS:-true}       # Enable semantic analysis
      - NLP_ANALYSIS_ENABLE_PHRASE_EXTRACTION=${NLP_ANALYSIS_ENABLE_PHRASE_EXTRACTION:-true}       # Enable phrase extraction
      - NLP_ANALYSIS_ENABLE_PATTERN_LEARNING=${NLP_ANALYSIS_ENABLE_PATTERN_LEARNING:-true}        # Enable pattern learning
      - NLP_ANALYSIS_INTEGRATION_MODE=${NLP_ANALYSIS_INTEGRATION_MODE:-full}               # Integration mode: minimal/standard/enhanced/full
      
      # ============== PERFORMANCE SETTINGS =======================================
      # Performance-related parameters for analysis algorithms
      - NLP_ANALYSIS_TIMEOUT_MS=${NLP_ANALYSIS_TIMEOUT_MS:-5000}                     # Analysis timeout in milliseconds
      - NLP_ANALYSIS_MAX_CONCURRENT=${NLP_ANALYSIS_MAX_CONCURRENT:-10}                   # Maximum concurrent analyses
      - NLP_ANALYSIS_ENABLE_CACHING=${NLP_ANALYSIS_ENABLE_CACHING:-true}                 # Enable analysis result caching
      - NLP_ANALYSIS_CACHE_TTL_SECONDS=${NLP_ANALYSIS_CACHE_TTL_SECONDS:-300}               # Cache TTL in seconds
      - NLP_ANALYSIS_ENABLE_PARALLEL_PROCESSING=${NLP_ANALYSIS_ENABLE_PARALLEL_PROCESSING:-true}     # Enable parallel processing
      
      # ============== DEBUGGING SETTINGS =========================================
      # Parameters for debugging and development
      - NLP_ANALYSIS_ENABLE_DETAILED_LOGGING=${NLP_ANALYSIS_ENABLE_DETAILED_LOGGING:-true}       # Enable detailed logging
      - NLP_ANALYSIS_LOG_ANALYSIS_STEPS=${NLP_ANALYSIS_LOG_ANALYSIS_STEPS:-false}            # Log individual analysis steps
      - NLP_ANALYSIS_INCLUDE_REASONING=${NLP_ANALYSIS_INCLUDE_REASONING:-true}              # Include reasoning in responses
      - NLP_ANALYSIS_ENABLE_PERFORMANCE_METRICS=${NLP_ANALYSIS_ENABLE_PERFORMANCE_METRICS:-true}     # Enable performance metrics
      
      # ============== EXPERIMENTAL FEATURES ======================================
      # Feature flags for experimental analysis features
      - NLP_ANALYSIS_EXPERIMENTAL_ADVANCED_CONTEXT=${NLP_ANALYSIS_EXPERIMENTAL_ADVANCED_CONTEXT:-false}    # Advanced context analysis
      - NLP_ANALYSIS_EXPERIMENTAL_COMMUNITY_VOCAB=${NLP_ANALYSIS_EXPERIMENTAL_COMMUNITY_VOCAB:-false}     # Community vocabulary boost
      - NLP_ANALYSIS_EXPERIMENTAL_TEMPORAL_PATTERNS=${NLP_ANALYSIS_EXPERIMENTAL_TEMPORAL_PATTERNS:-true}   # Temporal pattern detection
      - NLP_ANALYSIS_EXPERIMENTAL_MULTI_LANGUAGE=${NLP_ANALYSIS_EXPERIMENTAL_MULTI_LANGUAGE:-false}      # Multi-language support
    volumes:
      - ./ash-nlp/data:/app/data
      - ./ash-nlp/models/cache:/app/models/cache
      - ./ash-nlp/logs:/app/logs
      - ./ash-nlp/learning_data:/app/learning_data
      - ./secrets:/run/secrets:ro
    depends_on:
      ash-redis:
        condition: service_started
    deploy:
      resources:
        limits:
          memory: 8G
          cpus: '4.0'
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8881/health"]
      interval: 30s
      timeout: 15s
      retries: 3
      start_period: 60s

  # ========================================================================
  # Redis Cache
  # ========================================================================
  ash-redis:
    image: redis:7-alpine
    container_name: ash-redis
    restart: unless-stopped
    networks:
      ash-network:
        ipv4_address: 172.20.0.20
    ports:
      - 6379:6379
    command: redis-server --appendonly yes --requirepass ${GLOBAL_REDIS_PASSWORD}
    volumes:
      - redis_data:/data
      - ./secrets:/run/secrets:ro
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '0.25'
    healthcheck:
      test: ["CMD", "redis-cli", "--raw", "incr", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3

networks:
  ash-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16

volumes:
  redis_data:
    driver: local