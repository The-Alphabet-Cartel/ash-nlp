# .env file template for Ash's NLP Server
# Copy this file to .env and fill in your actual values

# Hugging Face token for model downloads
HUGGINGFACE_HUB_TOKEN=your_token_here

# Learning system configuration
ENABLE_LEARNING_SYSTEM=true
LEARNING_RATE=0.1
MAX_LEARNING_ADJUSTMENTS_PER_DAY=50
LEARNING_PERSISTENCE_FILE=./learning_data/adjustments.json
MIN_CONFIDENCE_ADJUSTMENT=0.05
MAX_CONFIDENCE_ADJUSTMENT=0.30

# Model configuration
DEPRESSION_MODEL=rafalposwiata/deproberta-large-depression
SENTIMENT_MODEL=cardiffnlp/twitter-roberta-base-sentiment-latest
MODEL_CACHE_DIR=./models/cache

# Auto-detect GPU/CPU
DEVICE=auto

# Performance tuning
MAX_BATCH_SIZE=32
INFERENCE_THREADS=4
MODEL_PRECISION=float16  # Use half-precision for RTX 3050

# Logging
LOG_LEVEL=INFO
LOG_FILE=nlp_service.log
PYTHONUNBUFFERED=1

# Server configuration
NLP_SERVICE_HOST=0.0.0.0
NLP_SERVICE_PORT=8881

# Example filled out:
# HUGGINGFACE_HUB_TOKEN=hf_abcdef1234567890...
# DEVICE=cuda  # or 'cpu' to force CPU usage
# LOG_LEVEL=DEBUG  # for more verbose logging during development