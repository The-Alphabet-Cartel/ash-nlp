# =============================================================================
# ASH NLP SERVICE CONFIGURATION - CENTRALIZED THRESHOLD MANAGEMENT
# Environment variables for the Enhanced NLP Service v4.3
# Repository: https://github.com/the-alphabet-cartel/ash-nlp
# Part of: The Alphabet Cartel (https://discord.gg/alphabetcartel) Ash Ecosystem
# =============================================================================

# =============================================================================
# HUGGING FACE CONFIGURATION
# =============================================================================
GLOBAL_HUGGINGFACE_TOKEN=/run/secrets/huggingface
NLP_HUGGINGFACE_CACHE_DIR=./models/cache

# =============================================================================
# LEARNING SYSTEM CONFIGURATION
# =============================================================================
GLOBAL_ENABLE_LEARNING_SYSTEM=true
NLP_LEARNING_RATE=0.1
NLP_MAX_LEARNING_ADJUSTMENTS_PER_DAY=50
NLP_LEARNING_PERSISTENCE_FILE=./learning_data/adjustments.json
NLP_MIN_CONFIDENCE_ADJUSTMENT=0.05
NLP_MAX_CONFIDENCE_ADJUSTMENT=0.30

# =============================================================================
# ADDITIONAL MODEL MANAGER SETTINGS
# =============================================================================
NLP_USE_FAST_TOKENIZER=true
NLP_TRUST_REMOTE_CODE=false  
NLP_MODEL_REVISION=main

# =============================================================================
# THREE-MODEL CONFIGURATION
# =============================================================================
NLP_DEPRESSION_MODEL=MoritzLaurer/deberta-v3-base-zeroshot-v2.0
NLP_SENTIMENT_MODEL=MoritzLaurer/mDeBERTa-v3-base-mnli-xnli
NLP_EMOTIONAL_DISTRESS_MODEL=Lowerated/lm6-deberta-v3-topic-sentiment
NLP_MODEL_CACHE_DIR=./models/cache

# =============================================================================
# ENSEMBLE CONFIGURATION
# =============================================================================
NLP_ENSEMBLE_MODE=consensus
NLP_GAP_DETECTION_THRESHOLD=0.25
NLP_DISAGREEMENT_THRESHOLD=0.35
NLP_AUTO_FLAG_DISAGREEMENTS=true

# Model weights (must sum to 1.0)
NLP_DEPRESSION_MODEL_WEIGHT=0.6
NLP_SENTIMENT_MODEL_WEIGHT=0.15
NLP_EMOTIONAL_DISTRESS_MODEL_WEIGHT=0.25

# =============================================================================
# HARDWARE CONFIGURATION
# =============================================================================
NLP_DEVICE=auto
NLP_MODEL_PRECISION=float16

# =============================================================================
# PERFORMANCE TUNING
# =============================================================================
NLP_MAX_BATCH_SIZE=32
NLP_INFERENCE_THREADS=16
NLP_MAX_CONCURRENT_REQUESTS=20
NLP_REQUEST_TIMEOUT=40

# =============================================================================
# SERVER CONFIGURATION
# =============================================================================
NLP_SERVICE_HOST=0.0.0.0
NLP_SERVICE_PORT=8881
NLP_UVICORN_WORKERS=1
NLP_RELOAD_ON_CHANGES=false

# =============================================================================
# LOGGING CONFIGURATION
# =============================================================================
GLOBAL_LOG_LEVEL=INFO
NLP_LOG_FILE=nlp_service.log
NLP_FLIP_SENTIMENT_LOGIC=false

# =============================================================================
# STORAGE PATHS
# =============================================================================
NLP_DATA_DIR=./data
NLP_MODELS_DIR=./models/cache
NLP_LOGS_DIR=./logs
NLP_LEARNING_DATA_DIR=./learning_data

# =============================================================================
# ZERO-SHOT LABELS CONFIGURATION
# =============================================================================
# Choose which label set to use for zero-shot classification
# Options: current, enhanced_crisis, clinical_focused, conversational, safety_first
NLP_ZERO_SHOT_LABEL_SET=enhanced_crisis

# Enable label set switching via API (for testing/development)
NLP_ENABLE_LABEL_SET_SWITCHING=true

# =============================================================================
# LABEL TESTING CONFIGURATION
# =============================================================================
# Enable detailed label analysis in responses (for debugging)
NLP_INCLUDE_RAW_LABELS=true

# Log label mapping decisions for analysis
NLP_LOG_LABEL_MAPPINGS=true

# Enable label performance tracking
NLP_TRACK_LABEL_PERFORMANCE=true

# =============================================================================
# Phase 3a - Crisis Pattern Configuration
# =============================================================================
NLP_CONFIG_ENABLE_CRISIS_PATTERNS=true
NLP_CONFIG_ENABLE_LGBTQIA_PATTERNS=true
NLP_CONFIG_ENABLE_POSITIVE_CONTEXTS=true
NLP_CONFIG_CRISIS_CONTEXT_BOOST_MULTIPLIER=1.0
NLP_CONFIG_LGBTQIA_WEIGHT_MULTIPLIER=1.0
NLP_CONFIG_BURDEN_WEIGHT_MULTIPLIER=1.2
NLP_CONFIG_ENHANCED_CRISIS_WEIGHT=1.2

# =============================================================================
# PHASE 3b - ANALYSIS PARAMETERS CONFIGURATION
# =============================================================================
# ============== CRISIS THRESHOLDS ==========================================
# Core crisis level mapping thresholds for analysis algorithms
NLP_ANALYSIS_CRISIS_THRESHOLD_HIGH=0.55    # Reduced from 0.50 - matches systematic approach
NLP_ANALYSIS_CRISIS_THRESHOLD_MEDIUM=0.28  # Reduced from 0.22 - more selective for medium alerts
NLP_ANALYSIS_CRISIS_THRESHOLD_LOW=0.16     # Reduced from 0.12 - avoids very mild expressions

# ============== PHRASE EXTRACTION PARAMETERS ===============================
# Parameters for crisis phrase extraction from messages
NLP_ANALYSIS_MIN_PHRASE_LENGTH=2           # Minimum length for extracted phrases
NLP_ANALYSIS_MAX_PHRASE_LENGTH=6           # Maximum length for extracted phrases
NLP_ANALYSIS_PHRASE_CRISIS_FOCUS=true      # Focus on crisis-related phrases
NLP_ANALYSIS_PHRASE_COMMUNITY_SPECIFIC=true # Use community-specific patterns
NLP_ANALYSIS_PHRASE_MIN_CONFIDENCE=0.3     # Minimum confidence for phrase extraction
NLP_ANALYSIS_PHRASE_MAX_RESULTS=20         # Maximum number of phrases to return

# ============== PATTERN LEARNING PARAMETERS ================================
# Parameters for learning distinctive crisis patterns from community messages
NLP_ANALYSIS_PATTERN_MIN_CRISIS_MESSAGES=10      # Minimum crisis messages for pattern learning
NLP_ANALYSIS_PATTERN_MAX_PHRASES_TO_ANALYZE=200  # Maximum phrases to analyze
NLP_ANALYSIS_PATTERN_MIN_DISTINCTIVENESS_RATIO=2.0 # Minimum distinctiveness ratio
NLP_ANALYSIS_PATTERN_MIN_FREQUENCY=3             # Minimum frequency for pattern detection
NLP_ANALYSIS_PATTERN_HIGH_CONFIDENCE=0.7         # High confidence threshold for patterns
NLP_ANALYSIS_PATTERN_MEDIUM_CONFIDENCE=0.4       # Medium confidence threshold for patterns
NLP_ANALYSIS_PATTERN_LOW_CONFIDENCE=0.1          # Low confidence threshold for patterns

# ============== SEMANTIC ANALYSIS PARAMETERS ===============================
# Parameters for semantic analysis and context understanding
NLP_ANALYSIS_SEMANTIC_CONTEXT_WINDOW=3           # Words around community terms
NLP_ANALYSIS_SEMANTIC_HIGH_RELEVANCE_BOOST=0.1   # Boost for high relevance context
NLP_ANALYSIS_SEMANTIC_MEDIUM_RELEVANCE_BOOST=0.05 # Boost for medium relevance context
NLP_ANALYSIS_SEMANTIC_FAMILY_REJECTION_BOOST=0.15 # Boost for family rejection indicators
NLP_ANALYSIS_SEMANTIC_DISCRIMINATION_FEAR_BOOST=0.15 # Boost for discrimination fear
NLP_ANALYSIS_SEMANTIC_SUPPORT_SEEKING_BOOST=-0.05    # Reduces crisis level (positive context)

# ============== ADVANCED ANALYSIS PARAMETERS ===============================
# Advanced analysis parameters for fine-tuning algorithm behavior
NLP_ANALYSIS_PATTERN_CONFIDENCE_BOOST=0.05       # Additional confidence boost from patterns
NLP_ANALYSIS_MODEL_CONFIDENCE_BOOST=0.0          # Additional confidence boost from models
NLP_ANALYSIS_CONTEXT_SIGNAL_WEIGHT=1.0           # Weight for context signals
NLP_ANALYSIS_TEMPORAL_URGENCY_MULTIPLIER=1.2     # Multiplier for temporal urgency
NLP_ANALYSIS_COMMUNITY_AWARENESS_BOOST=0.1       # Boost for community-aware analysis

# ============== INTEGRATION SETTINGS =======================================
# Settings for integrating analysis components
NLP_ANALYSIS_ENABLE_PATTERN_ANALYSIS=true        # Enable pattern-based analysis
NLP_ANALYSIS_ENABLE_SEMANTIC_ANALYSIS=true       # Enable semantic analysis
NLP_ANALYSIS_ENABLE_PHRASE_EXTRACTION=true       # Enable phrase extraction
NLP_ANALYSIS_ENABLE_PATTERN_LEARNING=true        # Enable pattern learning
NLP_ANALYSIS_INTEGRATION_MODE=full               # Integration mode: minimal/standard/enhanced/full

# ============== PERFORMANCE SETTINGS =======================================
# Performance-related parameters for analysis algorithms
NLP_ANALYSIS_TIMEOUT_MS=5000                     # Analysis timeout in milliseconds
NLP_ANALYSIS_MAX_CONCURRENT=10                   # Maximum concurrent analyses
NLP_ANALYSIS_ENABLE_CACHING=true                 # Enable analysis result caching
NLP_ANALYSIS_CACHE_TTL_SECONDS=300               # Cache TTL in seconds
NLP_ANALYSIS_ENABLE_PARALLEL_PROCESSING=true     # Enable parallel processing

# ============== DEBUGGING SETTINGS =========================================
# Parameters for debugging and development
NLP_ANALYSIS_ENABLE_DETAILED_LOGGING=true       # Enable detailed logging
NLP_ANALYSIS_LOG_ANALYSIS_STEPS=false            # Log individual analysis steps
NLP_ANALYSIS_INCLUDE_REASONING=true              # Include reasoning in responses
NLP_ANALYSIS_ENABLE_PERFORMANCE_METRICS=true     # Enable performance metrics

# ============== EXPERIMENTAL FEATURES ======================================
# Feature flags for experimental analysis features
NLP_ANALYSIS_EXPERIMENTAL_ADVANCED_CONTEXT=false    # Advanced context analysis
NLP_ANALYSIS_EXPERIMENTAL_COMMUNITY_VOCAB=true     # Community vocabulary boost
NLP_ANALYSIS_EXPERIMENTAL_TEMPORAL_PATTERNS=true   # Temporal pattern detection
NLP_ANALYSIS_EXPERIMENTAL_MULTI_LANGUAGE=false      # Multi-language support

# =============================================================================
# CENTRALIZED CRISIS THRESHOLD CONFIGURATION
# ALL thresholds in one place - NO hard-coded values in code
# =============================================================================
# ============== CONSENSUS PREDICTION MAPPING THRESHOLDS ====================
# These control how consensus predictions map to crisis levels
# Used in: ensemble_endpoints.py _map_to_crisis_level()

# CRISIS prediction thresholds
NLP_CONSENSUS_CRISIS_TO_HIGH_THRESHOLD=0.50     # crisis + confidence >= 0.50 → HIGH
NLP_CONSENSUS_CRISIS_TO_MEDIUM_THRESHOLD=0.30   # crisis + confidence >= 0.30 → MEDIUM
# crisis + confidence < 0.30 → LOW (any crisis prediction gets at least LOW)

# MILD_CRISIS prediction thresholds  
NLP_CONSENSUS_MILD_CRISIS_TO_LOW_THRESHOLD=0.40 # mild_crisis + confidence >= 0.40 → LOW
# mild_crisis + confidence < 0.40 → NONE

# NEGATIVE sentiment thresholds
NLP_CONSENSUS_NEGATIVE_TO_LOW_THRESHOLD=0.70    # negative + confidence >= 0.70 → LOW
# negative + confidence < 0.70 → NONE

# UNKNOWN prediction fallback
NLP_CONSENSUS_UNKNOWN_TO_LOW_THRESHOLD=0.50     # unknown + confidence > 0.50 → LOW (conservative)
# unknown + confidence <= 0.50 → NONE

# ============== ENSEMBLE FINAL SCORING THRESHOLDS ==========================
# These are applied after consensus mapping (if used elsewhere)
# Legacy support for any code still using these

NLP_ENSEMBLE_HIGH_CRISIS_THRESHOLD=0.45
NLP_ENSEMBLE_MEDIUM_CRISIS_THRESHOLD=0.25  
NLP_ENSEMBLE_LOW_CRISIS_THRESHOLD=0.12

# ============== INDIVIDUAL MODEL THRESHOLDS ===============================
# For backward compatibility with any legacy single-model code

NLP_HIGH_CRISIS_THRESHOLD=0.45
NLP_MEDIUM_CRISIS_THRESHOLD=0.25
NLP_LOW_CRISIS_THRESHOLD=0.15

# ============== STAFF REVIEW THRESHOLDS ====================================
# Controls when cases require staff review
NLP_STAFF_REVIEW_HIGH_ALWAYS=true                    # HIGH always needs review
NLP_STAFF_REVIEW_MEDIUM_CONFIDENCE_THRESHOLD=0.45    # MEDIUM + confidence >= 0.45 needs review
NLP_STAFF_REVIEW_LOW_CONFIDENCE_THRESHOLD=0.75       # LOW + confidence >= 0.75 needs review
NLP_STAFF_REVIEW_ON_MODEL_DISAGREEMENT=true          # Any gap detected needs review

# ============== SAFETY AND BIAS CONTROLS ===================================
NLP_CONSENSUS_SAFETY_BIAS=0.03                # Small boost toward higher crisis levels
NLP_ENABLE_SAFETY_OVERRIDE=true               # Allow severe individual results to override consensus

# ============== RATE LIMITING ==============================================
NLP_MAX_REQUESTS_PER_MINUTE=120
NLP_MAX_REQUESTS_PER_HOUR=2000

# ============== SECURITY ===================================================
GLOBAL_ALLOWED_IPS=10.20.30.0/24,127.0.0.1,::1
GLOBAL_ENABLE_CORS=true

# ============== EXPERIMENTAL FEATURES ======================================
NLP_ENABLE_ENSEMBLE_ANALYSIS=true
NLP_ENABLE_GAP_DETECTION=true
NLP_ENABLE_CONFIDENCE_SPREADING=true
NLP_LOG_MODEL_DISAGREEMENTS=true