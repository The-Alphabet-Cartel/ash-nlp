# Ash NLP Service üß†

> **Enhanced Mental Health Crisis Detection for Discord Bot Ash**  
> Safety-first AI model for identifying users who may need crisis intervention

[![FastAPI](https://img.shields.io/badge/FastAPI-4.0-009688.svg)](https://fastapi.tiangolo.com)
[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://python.org)
[![Transformers](https://img.shields.io/badge/ü§ó%20Transformers-4.35.2-yellow.svg)](https://huggingface.co/transformers)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

## Overview

Ash NLP Service is a specialized microservice that analyzes Discord messages to detect mental health crises with a **safety-first approach**. Built for the Ash Discord bot, it uses advanced NLP models to identify users who may be experiencing suicidal ideation, severe depression, or other mental health emergencies.

### üéØ **Core Mission**
**Zero missed crises** - The system prioritizes catching every genuine mental health emergency, even if it means some borderline cases get escalated to human review.

## Key Features

- üö® **100% High Crisis Detection** - Never misses critical cases requiring immediate intervention
- üß† **Multi-Model Analysis** - Combines depression detection with sentiment analysis for context
- üé≠ **Advanced Idiom Filtering** - Distinguishes between genuine distress and common expressions
- ‚ö° **Real-Time Processing** - <100ms response time for Discord integration
- üõ°Ô∏è **Safety-First Design** - Optimized to err on the side of caution
- üìä **Comprehensive Logging** - Detailed analysis reasoning for review and improvement

## Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Discord Bot   ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ   Ash NLP API    ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  Crisis Team    ‚îÇ
‚îÇ  (Keyword Pre-  ‚îÇ    ‚îÇ  (Nuanced ML     ‚îÇ    ‚îÇ   Response      ‚îÇ
‚îÇ   screening)    ‚îÇ    ‚îÇ   Analysis)      ‚îÇ    ‚îÇ                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Two-Tier Detection System

1. **Bot Level**: Fast keyword/phrase detection for obvious cases
2. **NLP Level**: Deep contextual analysis for nuanced cases

## Performance Metrics

| Metric | Target | Achieved |
|--------|--------|----------|
| **High Crisis Detection** | 90%+ | **100%** ‚úÖ |
| **Processing Time** | <100ms | ~90ms ‚úÖ |
| **False Positive Rate** | <20% | 15.8% ‚úÖ |
| **Uptime** | 99%+ | Production Ready ‚úÖ |

## Crisis Classification

### üö® **HIGH** (Immediate Response Required)
- Direct suicidal statements
- Specific suicide plans or methods
- Severe hopelessness expressions
- Burden ideation ("better off without me")

### ‚ö†Ô∏è **MEDIUM** (Professional Check-in Recommended)  
- Persistent sadness or depression
- Loss of hope or motivation
- Emotional emptiness
- Difficulty coping

### ‚ÑπÔ∏è **LOW** (Monitoring Suggested)
- Temporary stress or anxiety
- Sleep difficulties
- General life challenges
- Mild emotional distress

### ‚úÖ **NONE** (No Action Required)
- Normal conversation
- Positive expressions
- Idioms and hyperbole
- General questions

## Quick Start

### Prerequisites

- Python 3.8+
- 8GB+ RAM (for ML models)
- Docker (recommended)

### Docker Deployment (Recommended)

```bash
# Clone repository
git clone https://github.com/your-org/ash-nlp.git
cd ash-nlp

# Start service
docker-compose up -d

# Verify health
curl http://localhost:8881/health
```

### Manual Installation

```bash
# Install dependencies
pip install -r requirements.txt

# Start service
python main.py
```

## API Reference

### Analyze Message

**POST** `/analyze`

Analyzes a message for mental health crisis indicators.

```json
{
  "message": "I've been feeling really down lately",
  "user_id": "user123",
  "channel_id": "channel456"
}
```

**Response:**
```json
{
  "needs_response": true,
  "crisis_level": "medium",
  "confidence_score": 0.65,
  "detected_categories": ["moderate", "persistent_sadness"],
  "method": "enhanced_depression_model_with_context",
  "processing_time_ms": 87.3,
  "model_info": "depression+sentiment+context_analysis",
  "reasoning": "Context: {...} | Sentiment: {...} | Depression model: 0.65"
}
```

### Health Check

**GET** `/health`

Returns service health and model status.

### Statistics

**GET** `/stats`

Returns detailed performance metrics and configuration.

## Configuration

### Environment Variables

```bash
# Optional: Hugging Face token for model downloads
HUGGINGFACE_HUB_TOKEN=your_token_here

# Logging
PYTHONUNBUFFERED=1
```

### Docker Resource Limits

```yaml
deploy:
  resources:
    limits:
      memory: 8G      # Sufficient for ML models
      cpus: '4'       # Recommended for processing
    reservations:
      memory: 2G
      cpus: '1'
```

## Models Used

### Primary Models
- **Depression Detection**: `rafalposwiata/deproberta-large-depression`
  - DeBERTa-based model for depression severity classification
  - Labels: `not depression`, `moderate`, `severe`

- **Sentiment Analysis**: `cardiffnlp/twitter-roberta-base-sentiment-latest`
  - RoBERTa-based sentiment classification
  - Provides contextual understanding for better accuracy

### Model Pipeline
1. **Context Extraction** - Identifies humor, idioms, and situational context
2. **Depression Analysis** - Primary crisis classification
3. **Sentiment Integration** - Contextual validation
4. **Pattern Boosting** - Special handling for commonly missed patterns
5. **Idiom Filtering** - Reduces false positives from colloquial expressions
6. **Safety Mapping** - Conservative threshold application

## Safety Features

### Pattern Boosting
The system specifically watches for patterns that ML models often miss:

```python
# Burden ideation (often missed by models)
"better off without me" ‚Üí Forced HIGH classification

# Severe hopelessness
"everything feels pointless" ‚Üí Forced HIGH classification

# Severe struggle expressions  
"really struggling right now" ‚Üí Forced HIGH classification
```

### Idiom Protection
Advanced context-aware filtering prevents false positives:

```python
# Safe when in humor context
"that joke killed me" ‚Üí NONE (if humor detected)

# Safe when expressing fatigue
"dead tired" ‚Üí NONE (if no crisis indicators)

# Safe when expressing success
"killing it at work" ‚Üí NONE (if work context)
```

## Testing

### Run Test Suite

```bash
python final_realistic_test.py
```

### Test Coverage
- ‚úÖ 12 HIGH crisis scenarios (100% detection required)
- ‚úÖ 8 MEDIUM concern scenarios 
- ‚úÖ 8 LOW concern scenarios
- ‚úÖ 19 NONE scenarios (false positive testing)

## Monitoring & Logging

### Log Levels
- **INFO**: Normal operation and analysis results
- **ERROR**: Service failures and model issues
- **DEBUG**: Detailed reasoning and scoring

### Key Metrics to Monitor
- Response time (target: <100ms)
- Model accuracy on test cases
- False positive rates
- Memory usage (models are large)

## Development

### Local Development

```bash
# Enable local build in docker-compose.yml
# Uncomment build section, comment image section

# Hot reload during development
uvicorn main:app --reload --host 0.0.0.0 --port 8881
```

### Adding New Patterns

1. Update pattern libraries in `main.py`
2. Test with realistic scenarios
3. Verify safety metrics maintain >90% high detection
4. Update test suite accordingly

## Hardware Requirements

### Minimum
- **CPU**: 2+ cores
- **RAM**: 4GB
- **Storage**: 2GB (for models)

### Recommended (Production)
- **CPU**: AMD Ryzen 7 7700x or equivalent
- **RAM**: 8GB+ 
- **GPU**: Optional (currently CPU-optimized)

## Security Considerations

- ‚ö†Ô∏è **No data persistence** - Messages are processed and discarded
- üîí **No external API calls** - All processing is local
- üìù **Audit logging** - All analysis decisions are logged
- üö´ **No model training** - Read-only model usage

## Contributing

1. Fork the repository
2. Create a feature branch
3. Ensure all tests pass with >90% high crisis detection
4. Submit a pull request with safety impact analysis

### Safety-First Development Rules
1. **Never compromise high crisis detection** for overall accuracy
2. **Test with realistic scenarios** not academic datasets  
3. **Document safety impact** of any threshold changes
4. **Prefer false positives** over false negatives

## License

GNU General Public License-v3 - see [LICENSE](LICENSE) file for details.

## Support

- üìß **Issues**: GitHub Issues
- üìñ **Documentation**: This README and inline comments
- üîß **Configuration**: See `docker-compose.yml` and `main.py`

## Acknowledgments

- **Depression Model**: [rafalposwiata/deproberta-large-depression](https://huggingface.co/rafalposwiata/deproberta-large-depression)
- **Sentiment Model**: [cardiffnlp/twitter-roberta-base-sentiment-latest](https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment-latest)
- **Framework**: FastAPI, Transformers, PyTorch

---

**‚ö†Ô∏è Important**: This system is designed to assist human crisis responders, not replace them. All HIGH classifications should be reviewed by qualified mental health professionals.